# main.py - Medical RAG API —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Pinecone llama-text-embed-v2
import os
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import vertexai
from vertexai.generative_models import GenerativeModel
import pinecone
import httpx
import json
import traceback
import asyncio
from datetime import datetime, timezone

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    level=logging.INFO, # –£—Ä–æ–≤–µ–Ω—å INFO –¥–ª—è production, DEBUG –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
gemini_model = None
pinecone_index = None
pinecone_client = None # –ù–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç Pinecone –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
INITIALIZATION_ERROR = None # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
PROJECT_ID = os.environ.get("PROJECT_ID", "ai-project-26082025")
REGION = os.environ.get("REGION", "us-central1")
PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "medical-knowledge")
YANDEX_API_KEY = os.environ.get("YANDEX_API_KEY")
YANDEX_FOLDER_ID = os.environ.get("YANDEX_FOLDER_ID",'b1gatnfegvh5a9a5iovu')
YANDEX_GPT_MODEL_URI = f"gpt://{YANDEX_FOLDER_ID}/yandexgpt/latest" if YANDEX_FOLDER_ID else None
MAX_CONTEXT_LENGTH = int(os.environ.get("MAX_CONTEXT_LENGTH", 5000)) # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç
google_credentials_json = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")
# --- Lifespan handler –¥–ª—è FastAPI ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global gemini_model, pinecone_index, pinecone_client, INITIALIZATION_ERROR
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Medical RAG API...")

    try:
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vertex AI (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤)
        logger.info(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vertex AI: project={PROJECT_ID}, location={REGION}")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ credentials –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∫–∞–∫ JSON string
        google_credentials_json = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")

        if google_credentials_json:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º credentials –∏–∑ JSON string
            logger.info("üîê –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ credentials –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è GOOGLE_APPLICATION_CREDENTIALS_JSON")
            try:
                import json
                from google.oauth2 import service_account

                # –ü–∞—Ä—Å–∏–º JSON credentials
                credentials_info = json.loads(google_credentials_json)
                credentials = service_account.Credentials.from_service_account_info(credentials_info)

                vertexai.init(
                    project=PROJECT_ID,
                    location=REGION,
                    credentials=credentials
                )
                logger.info("‚úÖ Vertex AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å service account credentials")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å service account credentials: {e}")
                # fallback –Ω–∞ default credentials
                logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ default credentials –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç")
                vertexai.init(project=PROJECT_ID, location=REGION)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º default credentials (–µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –≤ Google Cloud)
            logger.info("üîê –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ default credentials")
            vertexai.init(project=PROJECT_ID, location=REGION)
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Google Gemini (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤)
        logger.info("üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ gemini-2.5-pro...")
        try:

            gemini_model = GenerativeModel("gemini-2.5-pro")
        except Exception as e25:
            logger.info("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å gemini-2.5-pro –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–æ–±—É–µ–º gemini-2.5-pro...")
            try:
                gemini_model = GenerativeModel("gemini-2.5-pro")
            except Exception as e15:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Gemini 2.5-pro: {e15}")
                gemini_model = None
        if gemini_model:
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Gemini –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å Gemini.")

        # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone (–¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
        logger.info("üîó –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone...")
        if not PINECONE_API_KEY:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PINECONE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        if not PINECONE_INDEX_NAME:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PINECONE_INDEX_NAME –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç Pinecone
        pinecone_client = pinecone.Pinecone(api_key=PINECONE_API_KEY)

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∏–Ω–¥–µ–∫—Å—É
        pinecone_index = pinecone_client.Index(PINECONE_INDEX_NAME)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        index_stats = pinecone_index.describe_index_stats()
        logger.info(f"‚úÖ Pinecone –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ò–Ω–¥–µ–∫—Å '{PINECONE_INDEX_NAME}' —Å–æ–¥–µ—Ä–∂–∏—Ç {index_stats.get('total_vector_count', 0)} –≤–µ–∫—Ç–æ—Ä–æ–≤.")
        logger.info(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {index_stats.get('dimension', 'N/A')}")
        logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: llama-text-embed-v2")

        INITIALIZATION_ERROR = None # –°–±—Ä–æ—Å –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

    except Exception as e:
        error_msg = f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}"
        logger.error(error_msg)
        logger.error(f"   Traceback: {traceback.format_exc()}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –µ—ë –≤ /health
        INITIALIZATION_ERROR = str(e)
        # –ù–µ –±—Ä–æ—Å–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å—Ç–∏–ª–æ—Å—å, –Ω–æ —Å –æ—à–∏–±–∫–æ–π

    logger.info("üü¢ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–æ–≤.")
    yield
    logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

# --- –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è FastAPI —Å lifespan handler ---
app = FastAPI(
    lifespan=lifespan,
    title="Medical RAG API",
    version="3.4.0-Pinecone-Llama-Only",
    description="API –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å RAG, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å Llama –æ—Ç Pinecone"
)

# --- Middleware ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏. –í production —É–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ origins.
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π ---
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Å–µ—Ö –Ω–µ –ø–æ–π–º–∞–Ω–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π."""
    logger.error(f"üö® –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "detail": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "error_type": type(exc).__name__,
            # –í production –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–π—Ç–µ traceback –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é!
            # "debug_info": traceback.format_exc()
        },
    )

# --- –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ---
class QuestionRequest(BaseModel):
    question: str
    mode: str = "knowledge_base" # 'knowledge_base', 'combined_ai', 'unified_ai', 'open_sources', 'complete_analysis'

class AnswerResponse(BaseModel):
    question: str
    answer: str
    sources: List[str]
    mode: str

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
async def search_knowledge_base(question: str, top_k: int = 3):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π Pinecone —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Llama."""
    global pinecone_index, pinecone_client

    if not pinecone_index:
        logger.warning("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–∏–Ω–¥–µ–∫—Å Pinecone –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω)")
        return ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"], ["–°–∏—Å—Ç–µ–º–∞"]

    try:
        logger.debug(f"üîç –ü–æ–∏—Å–∫ –≤ Pinecone –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{question}'...")

        # --- 1. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é Inference API Pinecone ---
        logger.debug("üß† –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é Pinecone Inference API...")

        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ –≤ asyncio.to_thread
        embedding_response = await asyncio.to_thread(
            pinecone_client.inference.embed,
            model="llama-text-embed-v2",
            inputs=[question], # –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            parameters={
                "input_type": "query", # –¢–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –∑–∞–ø—Ä–æ—Å
                "truncate": "END"      # –ö–∞–∫ –æ–±—Ä–µ–∑–∞—Ç—å, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            }
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞
        question_embedding = embedding_response.data[0].values
        logger.debug(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(question_embedding)})")

        # --- 2. –ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ) ---
        logger.debug("üîé –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")

        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ query –≤ asyncio.to_thread
        search_results = await asyncio.to_thread(
            pinecone_index.query,
            vector=question_embedding,
            top_k=top_k,
            include_metadata=True
        )
        logger.debug(f"   –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(search_results.matches)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")

        # --- 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
        contexts = []
        sources = []

        if search_results.matches:
            for match in search_results.matches:
                metadata = match.metadata or {}
                # –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –∫–ª—é—á–∏ –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∞—à–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Pinecone
                # –ù–∞–ø—Ä–∏–º–µ—Ä: 'content', 'text', 'chunk_text', 'preview'
                text = metadata.get('content') or metadata.get('text') or metadata.get('chunk_text') or metadata.get('preview') or f"–î–æ–∫—É–º–µ–Ω—Ç ID: {match.id}"
                contexts.append(text)

                source = metadata.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
                sources.append(source)
        else:
            logger.info("   –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.")
            contexts.append("–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.")
            sources.append("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")

        logger.debug(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(contexts)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        return contexts, sources

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Pinecone: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return ["–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"], ["Pinecone"]

async def generate_with_gemini(question: str, contexts: List[str]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini."""
    if not gemini_model:
        logger.warning("–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return "–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    try:
        context_text = "\n\n".join(contexts)
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if len(context_text) > MAX_CONTEXT_LENGTH:
            context_text = context_text[:MAX_CONTEXT_LENGTH] + f"... (–∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
            logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤.")

        prompt = f"""
        –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

üéØ –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞:
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–ù–µ —É—Ö–æ–¥–∏—Ç—å –æ—Ç —Ç–µ–º—ã ‚Äî —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É.
–§–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫—Ä–∞—Ç–∫–æ, –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –∫–∞–∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç.
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ:
¬´–í –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –º–æ–≥—É –ø–æ–∏—Å–∫–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é¬ª ‚Äî –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–∏—Å–∫.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏:
¬´–•–æ—á–µ—à—å, —è –ø–æ–∏—â—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É?¬ª
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç ¬´–¥–∞¬ª ‚Äî –≤—ã–ø–æ–ª–Ω–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫, –¥–∞–π —á–µ—Ç–∫–∏–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø–æ –ø—É–Ω–∫—Ç–∞–º, –µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ), –±–µ–∑ –ª–∏—à–Ω–∏—Ö –æ–±—â–∏—Ö —Ñ—Ä–∞–∑.
‚úÖ –ü—Ä–∞–≤–∏–ª–∞:
–ù–∏–∫–∞–∫–∏—Ö —à–∞–±–ª–æ–Ω–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤: –Ω–µ –ø–∏—à–∏ "–≠—Ç–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å", "–Ø –Ω–µ –≤—Ä–∞—á" –∏ —Ç.–ø.
–ù–µ –≤–≤–æ–¥–∏ –Ω–æ–≤—ã–µ —Ç–µ–º—ã: –Ω–µ –æ–±—Å—É–∂–¥–∞–π —Ç–æ, –æ —á—ë–º –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏. –ü–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–º–æ—Ç—Ä–∏ –∑–∞–ø—Ä–æ—Å
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ:
¬´–í –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –º–æ–≥—É –ø–æ–∏—Å–∫–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é¬ª ‚Äî –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–∏—Å–∫.
–ü—Ä–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî —É–∫–∞–∂–∏: ¬´–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–Ω—ã–µ –º–Ω–µ–Ω–∏—è¬ª –∏ –∫—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ –∫–∞–∂–¥–æ–µ.
–ü–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º, –ø–æ–ª–Ω—ã–º, –≥–ª—É–±–æ–∫–∏–º.
–ü–æ–¥–∞–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –ø—É–Ω–∫—Ç–∞–º, –µ—Å–ª–∏ —ç—Ç–æ —É–ª—É—á—à–∞–µ—Ç —è—Å–Ω–æ—Å—Ç—å.
–ë–µ–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Ç–∏–ø–∞ "–æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –º–∞—Å—Ç–µ—Ä–∞–º" –∏–ª–∏ "—Å–æ–±–ª—é–¥–∞–π—Ç–µ –≥–∏–≥–∏–µ–Ω—É" ‚Äî —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–ø—Ä—è–º—É—é –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –≤–æ–ø—Ä–æ—Å—É.
–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Å–ø—Ä–æ—Å–∏:
¬´–ù—É–∂–Ω–æ –ª–∏ —á—Ç–æ-—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ –Ω–∞–π—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ?¬ª
      –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context_text}

        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç:
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini...")
        response = gemini_model.generate_content(prompt)
        answer = response.text.strip()
        logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Google Gemini —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {str(e)}"

async def generate_with_yandex(question: str, contexts: List[str]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT."""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        logger.warning("Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    try:
        context_text = "\n\n".join(contexts)
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if len(context_text) > MAX_CONTEXT_LENGTH:
            context_text = context_text[:MAX_CONTEXT_LENGTH] + f"... (–∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
            logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤.")

        prompt = f"""
                –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

üéØ –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞:
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–ù–µ —É—Ö–æ–¥–∏—Ç—å –æ—Ç —Ç–µ–º—ã ‚Äî —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É.
–§–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫—Ä–∞—Ç–∫–æ, –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –∫–∞–∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç.
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ:
¬´–í –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –º–æ–≥—É –ø–æ–∏—Å–∫–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é¬ª ‚Äî –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–∏—Å–∫.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏:
¬´–•–æ—á–µ—à—å, —è –ø–æ–∏—â—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É?¬ª
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç ¬´–¥–∞¬ª ‚Äî –≤—ã–ø–æ–ª–Ω–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫, –¥–∞–π —á–µ—Ç–∫–∏–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø–æ –ø—É–Ω–∫—Ç–∞–º, –µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ), –±–µ–∑ –ª–∏—à–Ω–∏—Ö –æ–±—â–∏—Ö —Ñ—Ä–∞–∑.
‚úÖ –ü—Ä–∞–≤–∏–ª–∞:
–ù–∏–∫–∞–∫–∏—Ö —à–∞–±–ª–æ–Ω–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤: –Ω–µ –ø–∏—à–∏ "–≠—Ç–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å", "–Ø –Ω–µ –≤—Ä–∞—á" –∏ —Ç.–ø.
–ù–µ –≤–≤–æ–¥–∏ –Ω–æ–≤—ã–µ —Ç–µ–º—ã: –Ω–µ –æ–±—Å—É–∂–¥–∞–π —Ç–æ, –æ —á—ë–º –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏. –ü–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–º–æ—Ç—Ä–∏ –∑–∞–ø—Ä–æ—Å
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî —Å–∫–∞–∂–∏ –ø—Ä—è–º–æ:
¬´–í –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –º–æ–≥—É –ø–æ–∏—Å–∫–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é¬ª ‚Äî –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–∏—Å–∫.
–ü—Ä–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî —É–∫–∞–∂–∏: ¬´–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–Ω—ã–µ –º–Ω–µ–Ω–∏—è¬ª –∏ –∫—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ –∫–∞–∂–¥–æ–µ.
–ü–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º, –ø–æ–ª–Ω—ã–º, –≥–ª—É–±–æ–∫–∏–º.
–ü–æ–¥–∞–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –ø—É–Ω–∫—Ç–∞–º, –µ—Å–ª–∏ —ç—Ç–æ —É–ª—É—á—à–∞–µ—Ç —è—Å–Ω–æ—Å—Ç—å.
–ë–µ–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Ç–∏–ø–∞ "–æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –º–∞—Å—Ç–µ—Ä–∞–º" –∏–ª–∏ "—Å–æ–±–ª—é–¥–∞–π—Ç–µ –≥–∏–≥–∏–µ–Ω—É" ‚Äî —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–ø—Ä—è–º—É—é –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –≤–æ–ø—Ä–æ—Å—É.
–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Å–ø—Ä–æ—Å–∏:
¬´–ù—É–∂–Ω–æ –ª–∏ —á—Ç–æ-—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ –Ω–∞–π—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ?¬ª
      –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context_text}

        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç:
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT...")
        async with httpx.AsyncClient() as client:
            yandex_response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.1,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            yandex_response.raise_for_status()
            yandex_data = yandex_response.json()
            answer = yandex_data['result']['alternatives'][0]['message']['text'].strip()
            logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Yandex GPT —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
            return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {str(e)}"

# –ù–æ–≤—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
async def generate_without_context(question: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è)"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è.
    –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ.
    –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —Å–∫–∞–∂–∏.
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_without_context_yandex(question: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Yandex GPT"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è.
    –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ.
    –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —Å–∫–∞–∂–∏.
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.7,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            response.raise_for_status()
            data = response.json()
            return data['result']['alternatives'][0]['message']['text'].strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ Yandex: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_with_context(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ Gemini"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
    
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    {context}
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_with_context_yandex(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ Yandex GPT"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
    
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    {context}
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.7,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            response.raise_for_status()
            data = response.json()
            return data['result']['alternatives'][0]['message']['text'].strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º Yandex: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

def search_open_sources(question: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"""
    sources = []

    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ API –∏–ª–∏ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

    sources.append({
        "name": "MedlinePlus (NIH)",
        "url": "https://medlineplus.gov",
        "content": "–û–±—â–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤ –∑–¥–æ—Ä–æ–≤—å—è –°–®–ê. –ò—Å—Ç–æ—á–Ω–∏–∫ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è—Ö, –ª–µ–∫–∞—Ä—Å—Ç–≤–∞—Ö –∏ –∑–¥–æ—Ä–æ–≤—å–µ."
    })

    sources.append({
        "name": "WHO - –í—Å–µ–º–∏—Ä–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
        "url": "https://who.int",
        "content": "–ì–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–Ω–¥–µ–º–∏—è—Ö, –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ."
    })

    sources.append({
        "name": "PubMed Central",
        "url": "https://ncbi.nlm.nih.gov/pmc",
        "content": "–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏ –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞—Ç–µ–π. –ù–∞—É—á–Ω—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ –≤—Å–µ–º –∞—Å–ø–µ–∫—Ç–∞–º –º–µ–¥–∏—Ü–∏–Ω—ã."
    })

    sources.append({
        "name": "Cochrane Library",
        "url": "https://cochranelibrary.com",
        "content": "–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–±–∑–æ—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π. –î–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞ –∏ –º–µ—Ç–∞-–∞–Ω–∞–ª–∏–∑—ã –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π."
    })

    sources.append({
        "name": "CDC - –¶–µ–Ω—Ç—Ä—ã –ø–æ –∫–æ–Ω—Ç—Ä–æ–ª—é –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –°–®–ê",
        "url": "https://cdc.gov",
        "content": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π, —ç–ø–∏–¥–µ–º–∏–æ–ª–æ–≥–∏–∏, –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–º –∑–¥–æ—Ä–æ–≤—å–µ."
    })

    return sources

# –ù–æ–≤—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è open_sources —Ä–µ–∂–∏–º–∞
async def generate_with_gemini_open_sources(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    try:
        prompt = f"""
        –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        {context}
        
        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏):
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini (open sources)...")
        response = gemini_model.generate_content(prompt)
        answer = response.text.strip()
        logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Google Gemini (open sources) —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini (open sources): {e}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {str(e)}"

async def generate_with_yandex_open_sources(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    try:
        prompt = f"""
        –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        {context}
        
        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏):
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT (open sources)...")
        async with httpx.AsyncClient() as client:
            yandex_response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.1,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            yandex_response.raise_for_status()
            yandex_data = yandex_response.json()
            answer = yandex_data['result']['alternatives'][0]['message']['text'].strip()
            logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Yandex GPT (open sources) —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
            return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT (open sources): {e}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {str(e)}"

# –ù–æ–≤—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è complete_analysis
async def generate_with_gemini_complete(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    try:
        prompt = f"""
        –ê–ù–ê–õ–ò–ó–ò–†–£–ô –°–õ–ï–î–£–Æ–©–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò –ü–†–ï–î–û–°–¢–ê–í–¨ –ö–†–ê–¢–ö–ò–ô, –ù–û –ü–û–õ–ù–´–ô –û–¢–í–ï–¢:
        
        –í–û–ü–†–û–°: {question}
        
        –ö–û–ù–¢–ï–ö–°–¢:
        {context}
        
        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º.
        """

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini (complete)...")
        response = gemini_model.generate_content(prompt)
        answer = response.text.strip()
        logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Google Gemini (complete) —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini (complete): {e}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {str(e)}"

async def generate_with_yandex_complete(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    try:
        prompt = f"""
        –ê–ù–ê–õ–ò–ó–ò–†–£–ô –°–õ–ï–î–£–Æ–©–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ –ò –ü–†–ï–î–û–°–¢–ê–í–¨ –ö–†–ê–¢–ö–ò–ô, –ù–û –ü–û–õ–ù–´–ô –û–¢–í–ï–¢:
        
        –í–û–ü–†–û–°: {question}
        
        –ö–û–ù–¢–ï–ö–°–¢:
        {context}
        
        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º.
        """

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT (complete)...")
        async with httpx.AsyncClient() as client:
            yandex_response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.1,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π —Ç–æ—á–Ω—ã–µ, –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            yandex_response.raise_for_status()
            yandex_data = yandex_response.json()
            answer = yandex_data['result']['alternatives'][0]['message']['text'].strip()
            logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Yandex GPT (complete) —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
            return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT (complete): {e}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {str(e)}"

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã API ---
@app.get("/")
async def home():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
    try:
        vector_count = 0
        dimension = 'N/A'
        if pinecone_index:
            try:
                stats = pinecone_index.describe_index_stats()
                vector_count = stats.get('total_vector_count', 0)
                dimension = stats.get('dimension', 'N/A')
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Pinecone –≤ /: {e}")
                vector_count = f"–û—à–∏–±–∫–∞: {e}"
        else:
            vector_count = "–ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"

        return {
            "status": "ok",
            "message": "Medical RAG API Server (Pinecone Llama Embeddings + Vertex AI)",
            "version": "3.4.0-Pinecone-Llama-Only",
            "pinecone_vectors": vector_count,
            "vector_dimension": dimension,
            "pinecone_embedding_model": "llama-text-embed-v2",
            "models_initialized": {
                "gemini_model": gemini_model is not None,
                "pinecone_index": pinecone_index is not None,
                "pinecone_client": pinecone_client is not None
            },
            "initialization_error": INITIALIZATION_ERROR
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Pinecone
        pinecone_status = "uninitialized"
        vector_count = 0
        dimension = 'N/A'
        if pinecone_index is not None:
            try:
                stats = pinecone_index.describe_index_stats()
                pinecone_status = "healthy"
                vector_count = stats.get('total_vector_count', 0)
                dimension = stats.get('dimension', 'N/A')
            except Exception as e:
                pinecone_status = "unhealthy"
                logger.error(f"Health check - Pinecone error: {e}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
        gemini_model_status = "healthy" if gemini_model is not None else "uninitialized"
        pinecone_client_status = "healthy" if pinecone_client is not None else "uninitialized"
        pinecone_index_status = "healthy" if pinecone_index is not None else "uninitialized"

        overall_status = "healthy"
        if not all([
            pinecone_status == "healthy",
            gemini_model_status == "healthy",
            pinecone_client_status == "healthy",
            pinecone_index_status == "healthy"
        ]):
            if INITIALIZATION_ERROR:
                overall_status = "unhealthy"
            else:
                overall_status = "degraded"

        return {
            "status": overall_status,
            "components": {
                "pinecone": {
                    "status": pinecone_status,
                    "vector_count": vector_count,
                    "dimension": dimension,
                    "embedding_model": "llama-text-embed-v2"
                },
                "gemini_model": {
                    "status": gemini_model_status
                },
                "pinecone_client": {
                    "status": pinecone_client_status
                },
                "pinecone_index": {
                    "status": pinecone_index_status
                }
            },
            "initialization_error": INITIALIZATION_ERROR,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ /health: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG.
    """
    question = request.question.strip()
    mode = request.mode
    logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: {question} (—Ä–µ–∂–∏–º: {mode})")

    # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not question:
        logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å")
        raise HTTPException(status_code=400, detail="–í–æ–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    if len(question) > 1000:
        logger.warning(f"–ü–æ–ª—É—á–µ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å ({len(question)} —Å–∏–º–≤–æ–ª–æ–≤)")
        raise HTTPException(status_code=400, detail="–í–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º 1000 —Å–∏–º–≤–æ–ª–æ–≤)")

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    if not gemini_model and not (YANDEX_API_KEY and YANDEX_FOLDER_ID):
        error_msg = "–°–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤: –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
        logger.error(error_msg)
        raise HTTPException(status_code=500, detail=error_msg)
    if not pinecone_index or not pinecone_client:
        error_msg = "–°–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤: –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
        logger.error(error_msg)
        raise HTTPException(status_code=500, detail=error_msg)

    try:
        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        answer = ""
        sources = []

        if mode == "knowledge_base":
            # –¢–æ–ª—å–∫–æ –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            contexts, sources = await search_knowledge_base(question, top_k=3)
            answer = "–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n\n" + "\n\n---\n\n".join(contexts)

        elif mode == "combined_ai":
            # –ü–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ò–ò + –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            contexts, sources = await search_knowledge_base(question, top_k=3)
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(contexts)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            if not contexts or contexts == ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"]:
                answer = "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
                sources = ["–°–∏—Å—Ç–µ–º–∞"]
            else:
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                tasks = []
                models_used = []

                if gemini_model:
                    tasks.append(generate_with_gemini(question, contexts))
                    models_used.append("Google Gemini")
                if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                    tasks.append(generate_with_yandex(question, contexts))
                    models_used.append("Yandex GPT")

                if tasks:
                    answers = await asyncio.gather(*tasks, return_exceptions=True)

                    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                    model_answers = []
                    for model_name, ans in zip(models_used, answers):
                        if isinstance(ans, Exception):
                            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                            model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                        else:
                            model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    unified_prompt = f"""
                    –í–æ–ø—Ä–æ—Å: {question}
                    
                    –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                    {'\n\n'.join(model_answers)}
                    
                    –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                    –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                    """

                    unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                    if gemini_model:
                        try:
                            unified_response = gemini_model.generate_content(unified_prompt)
                            unified_answer = unified_response.text.strip()
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    answer_parts = model_answers.copy()
                    answer_parts.append(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}")
                    answer = "\n\n---\n\n".join(answer_parts)
                else:
                    answer = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
                    sources = ["–°–∏—Å—Ç–µ–º–∞"]

        elif mode == "unified_ai":
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            answer = "üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...\n\n"

            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            empty_contexts = []

            tasks = []
            models_used = []

            if gemini_model:
                tasks.append(generate_with_gemini(question, empty_contexts))
                models_used.append("Google Gemini")
            if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                tasks.append(generate_with_yandex(question, empty_contexts))
                models_used.append("Yandex GPT")

            if tasks:
                answers = await asyncio.gather(*tasks, return_exceptions=True)

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                model_answers = []
                for model_name, ans in zip(models_used, answers):
                    if isinstance(ans, Exception):
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                        model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                    else:
                        model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                unified_prompt = f"""
                –í–æ–ø—Ä–æ—Å: {question}
                
                –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                {'\n\n'.join(model_answers)}
                
                –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                """

                unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                if gemini_model:
                    try:
                        unified_response = gemini_model.generate_content(unified_prompt)
                        unified_answer = unified_response.text.strip()
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                answer_parts = model_answers.copy()
                answer_parts.append(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}")
                answer += "\n\n---\n\n".join(answer_parts)
                sources = ["Google Gemini", "Yandex GPT", "–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
            else:
                answer = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
                sources = ["–°–∏—Å—Ç–µ–º–∞"]

        elif mode == "open_sources":
            # –ü–æ–∏—Å–∫ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º + –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ò–ò
            open_sources_info = search_open_sources(question)
            sources = [src["name"] for src in open_sources_info]

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            open_contexts = []
            for src in open_sources_info:
                open_contexts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {src['name']}\n{src['content']}")

            context_text = "\n\n".join(open_contexts) if open_contexts else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ò–ò –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            tasks = []
            models_used = []

            if gemini_model:
                tasks.append(generate_with_gemini_open_sources(question, context_text))
                models_used.append("Google Gemini")
            if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                tasks.append(generate_with_yandex_open_sources(question, context_text))
                models_used.append("Yandex GPT")

            if tasks:
                answers = await asyncio.gather(*tasks, return_exceptions=True)

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                model_answers = []
                for model_name, ans in zip(models_used, answers):
                    if isinstance(ans, Exception):
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                        model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                    else:
                        model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                unified_prompt = f"""
                –í–æ–ø—Ä–æ—Å: {question}
                
                –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
                {context_text}
                
                –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                {'\n\n'.join(model_answers)}
                
                –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                """

                unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                if gemini_model:
                    try:
                        unified_response = gemini_model.generate_content(unified_prompt)
                        unified_answer = unified_response.text.strip()
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                answer_parts = [
                    f"üìö –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n{context_text}",
                    *model_answers,
                    f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}"
                ]
                answer = "\n\n---\n\n".join(answer_parts)
            else:
                answer = f"üìö –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n{context_text}\n\n–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"

        elif mode == "complete_analysis":
            # –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó: –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π + –æ—Ç–∫—Ä—ã—Ç—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ + –ò–ò
            logger.info("üöÄ –ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")

            # 1. –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            kb_contexts, kb_sources = await search_knowledge_base(question, top_k=3)
            logger.info(f"   –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: –Ω–∞–π–¥–µ–Ω–æ {len(kb_contexts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            # 2. –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            open_sources_info = search_open_sources(question)
            open_sources = [src["name"] for src in open_sources_info]
            logger.info(f"   –û—Ç–∫—Ä—ã—Ç—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–∞–π–¥–µ–Ω–æ {len(open_sources_info)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

            # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            full_context_parts = []

            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            if kb_contexts and kb_contexts != ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"]:
                kb_text = "\n\n".join(kb_contexts)
                full_context_parts.append(f"–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:\n{kb_text}")

            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            if open_sources_info:
                open_contexts = []
                for src in open_sources_info:
                    open_contexts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {src['name']}\n{src['content']}")
                open_text = "\n\n".join(open_contexts)
                full_context_parts.append(f"–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –û–¢–ö–†–´–¢–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í:\n{open_text}")

            full_context = "\n\n" + "\n\n" + "="*50 + "\n\n".join(full_context_parts) + "\n" + "="*50

            # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –æ—Ç –ò–ò
            ai_answers = []
            models_used = []

            # Google Gemini
            if gemini_model:
                try:
                    gemini_answer = await generate_with_gemini_complete(question, full_context)
                    ai_answers.append(f"–û–¢–í–ï–¢ –û–¢ GOOGLE GEMINI:\n{gemini_answer}")
                    models_used.append("Google Gemini")
                    logger.info("   ‚úÖ Google Gemini: –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
                except Exception as e:
                    logger.error(f"   ‚ùå Google Gemini –æ—à–∏–±–∫–∞: {e}")
                    ai_answers.append(f"–û–¢–í–ï–¢ –û–¢ GOOGLE GEMINI:\n–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

            # Yandex GPT
            if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                try:
                    yandex_answer = await generate_with_yandex_complete(question, full_context)
                    ai_answers.append(f"–û–¢–í–ï–¢ –û–¢ YANDEX GPT:\n{yandex_answer}")
                    models_used.append("Yandex GPT")
                    logger.info("   ‚úÖ Yandex GPT: –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
                except Exception as e:
                    logger.error(f"   ‚ùå Yandex GPT –æ—à–∏–±–∫–∞: {e}")
                    ai_answers.append(f"–û–¢–í–ï–¢ –û–¢ YANDEX GPT:\n–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

            # 5. –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            if ai_answers:
                final_prompt = f"""
                –í–´–ü–û–õ–ù–ò–¢–ï –ü–û–õ–ù–´–ô –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –°–õ–ï–î–£–Æ–©–ï–ì–û –í–û–ü–†–û–°–ê:
                
                –í–û–ü–†–û–°: {question}
                
                –ü–û–õ–£–ß–ï–ù–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
                {full_context}
                
                –ê–ù–ê–õ–ò–ó–´ –û–¢ –°–ò–°–¢–ï–ú –ò–ò:
                {'\n\n'.join(ai_answers)}
                
                –ó–ê–î–ê–ß–ê:
                –°–æ–∑–¥–∞–π—Ç–µ –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å.
                –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
                –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–º.
                
                –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
                1. –ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –ü–†–û–Ø–í–õ–ï–ù–ò–Ø
                2. –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ï –ö–†–ò–¢–ï–†–ò–ò
                3. –ö–õ–ò–ù–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨
                4. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
                5. –ò–°–¢–û–ß–ù–ò–ö–ò –ò–ù–§–û–†–ú–ê–¶–ò–ò
                
                –í–ê–ñ–ù–û: –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —É–∫–∞–∂–∏—Ç–µ.
                –ù–ï –í–´–î–£–ú–´–í–ê–ô–¢–ï –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
                """

                try:
                    if gemini_model:
                        final_response = gemini_model.generate_content(final_prompt)
                        final_answer = final_response.text.strip()
                        logger.info("   ‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
                    else:
                        final_answer = "–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
                except Exception as e:
                    logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
                    final_answer = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
            else:
                final_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑—ã –æ—Ç —Å–∏—Å—Ç–µ–º –ò–ò"

            # 6. –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            answer = f"–ü–û–õ–ù–´–ô –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ê–ù–ê–õ–ò–ó\n\n{final_answer}"

            # 7. –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            all_sources = []
            if kb_sources and kb_sources != ["–°–∏—Å—Ç–µ–º–∞"]:
                all_sources.extend(kb_sources)
            all_sources.extend(open_sources)
            all_sources.extend(models_used)
            sources = list(set(all_sources))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

            logger.info("‚úÖ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

        else:
            raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ä–µ–∂–∏–º")

        # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç
        logger.info("‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
        return AnswerResponse(
            question=question,
            answer=answer,
            sources=sources,
            mode=mode
        )

    except HTTPException:
        # –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º HTTPException –∫–∞–∫ –µ—Å—Ç—å
        raise
    except Exception as e:
        logger.error(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ /ask: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

# --- –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ ---
if __name__ == "__main__":
    import uvicorn
    from datetime import datetime
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π Cloud Run/Render
    port = int(os.environ.get("PORT", 8080))
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ Uvicorn –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    # –í–ê–ñ–ù–û: host –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "0.0.0.0" –¥–ª—è Cloud Run/Render
    uvicorn.run(app, host="0.0.0.0", port=port)
