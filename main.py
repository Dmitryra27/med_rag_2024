# main.py - Medical RAG API —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Pinecone llama-text-embed-v2
import os
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pinecone import Pinecone
from pydantic import BaseModel
from typing import List, Optional
import vertexai
from vertexai.generative_models import GenerativeModel
import pinecone
import httpx
import json
import traceback
import asyncio
from datetime import datetime, timezone
import requests

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    level=logging.INFO, # –£—Ä–æ–≤–µ–Ω—å INFO –¥–ª—è production, DEBUG –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
gemini_model = None
pinecone_index = None
pinecone_client = None # –ù–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç Pinecone –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
INITIALIZATION_ERROR = None # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
PROJECT_ID = os.environ.get("PROJECT_ID", "ai-project-26082025")
REGION = os.environ.get("REGION", "us-central1")
PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.environ.get("PINECONE_INDEX_NAME", "medical-knowledge")

YANDEX_API_KEY = os.environ.get("YANDEX_API_KEY")
YANDEX_FOLDER_ID = os.environ.get("YANDEX_FOLDER_ID",'b1gatnfegvh5a9a5iovu')
YANDEX_GPT_MODEL_URI = f"gpt://{YANDEX_FOLDER_ID}/yandexgpt/latest" if YANDEX_FOLDER_ID else None
MAX_CONTEXT_LENGTH = int(os.environ.get("MAX_CONTEXT_LENGTH", 5000)) # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

# --- Lifespan handler –¥–ª—è FastAPI ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global gemini_model, pinecone_index, pinecone_client, INITIALIZATION_ERROR
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Medical RAG API...")

    try:
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vertex AI (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤)
        logger.info(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vertex AI: project={PROJECT_ID}, location={REGION}")
        vertexai.init(project=PROJECT_ID, location=REGION)
        logger.info("‚úÖ Vertex AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")

        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Google Gemini (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤)
        logger.info("üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ gemini-2.5-pro...")
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ 2.5-pro, –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º 1.5-pro
            gemini_model = GenerativeModel("gemini-2.5-pro")
        except Exception as e25:
            logger.info("‚ö†Ô∏è  –ú–æ–¥–µ–ª—å gemini-2.5-pro –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–æ–±—É–µ–º gemini-2.5-pro...")
            try:
                gemini_model = GenerativeModel("gemini-2.5-pro")
            except Exception as e15:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Gemini 2.5-pro: {e15}")
                gemini_model = None
        if gemini_model:
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Gemini –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å Gemini.")

        # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone (–¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)
        logger.info("üîó –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone...")
        if not PINECONE_API_KEY:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PINECONE_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")
        if not PINECONE_INDEX_NAME:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PINECONE_INDEX_NAME –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç Pinecone
        pinecone_client = pinecone.Pinecone(api_key=PINECONE_API_KEY)
        pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∏–Ω–¥–µ–∫—Å—É
        pinecone_index = pinecone_client.Index(PINECONE_INDEX_NAME)
        index = pinecone_client.Index(PINECONE_INDEX_NAME)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        index_stats = pinecone_index.describe_index_stats()
        logger.info(f"‚úÖ Pinecone –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ò–Ω–¥–µ–∫—Å '{PINECONE_INDEX_NAME}' —Å–æ–¥–µ—Ä–∂–∏—Ç {index_stats.get('total_vector_count', 0)} –≤–µ–∫—Ç–æ—Ä–æ–≤.")
        logger.info(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {index_stats.get('dimension', 'N/A')}")
        logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: llama-text-embed-v2")

        INITIALIZATION_ERROR = None # –°–±—Ä–æ—Å –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏

    except Exception as e:
        error_msg = f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}"
        logger.error(error_msg)
        logger.error(f"   Traceback: {traceback.format_exc()}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –µ—ë –≤ /health
        INITIALIZATION_ERROR = str(e)
        # –ù–µ –±—Ä–æ—Å–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å—Ç–∏–ª–æ—Å—å, –Ω–æ —Å –æ—à–∏–±–∫–æ–π

    logger.info("üü¢ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–æ–≤.")
    yield
    logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

# --- –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è FastAPI —Å lifespan handler ---
app = FastAPI(
    lifespan=lifespan,
    title="Medical RAG API",
    version="3.4.0-Pinecone-Llama-Only",
    description="API –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å RAG, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å Llama –æ—Ç Pinecone"
)

# --- Middleware ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏. –í production —É–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ origins.
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π ---
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Å–µ—Ö –Ω–µ –ø–æ–π–º–∞–Ω–Ω—ã—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π."""
    logger.error(f"üö® –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "detail": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "error_type": type(exc).__name__,
            # –í production –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–π—Ç–µ traceback –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é!
            # "debug_info": traceback.format_exc()
        },
    )

# --- –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö ---
class QuestionRequest(BaseModel):
    question: str
    mode: str = "knowledge_base" # 'knowledge_base', 'combined_ai'

class AnswerResponse(BaseModel):
    question: str
    answer: str
    sources: List[str]
    mode: str

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
# main.py (–Ω–∞ Render) - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ñ—É–Ω–∫—Ü–∏–∏ search_knowledge_base

# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –∫–ª–∏–µ–Ω—Ç–∞ Pinecone
# –û–±—ã—á–Ω–æ —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤ lifespan handler:
# pc = Pinecone(api_key=PINECONE_API_KEY)

async def search_knowledge_base(question: str, top_k: int = 3):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π Pinecone —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Llama."""
    global pinecone_index, pinecone_client

    if not pinecone_index:
        logger.warning("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–∏–Ω–¥–µ–∫—Å Pinecone –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω)")
        return ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"], ["–°–∏—Å—Ç–µ–º–∞"]

    try:
        logger.debug(f"üîç –ü–æ–∏—Å–∫ –≤ Pinecone –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{question}'...")

        # --- 1. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é Inference API Pinecone (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ) ---
        logger.debug("üß† –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é Pinecone Inference API...")

        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ –≤ asyncio.to_thread
        embedding_response = await asyncio.to_thread(
            pinecone_client.inference.embed,
            model="llama-text-embed-v2",
            inputs=[question],
            parameters={
                "input_type": "query",
                "truncate": "END"
            }

        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞
        question_embedding = embedding_response.data[0].values
        logger.debug(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(question_embedding)})")

        # --- 2. –ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ) ---
        logger.debug("üîé –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")

        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤ query –≤ asyncio.to_thread
        search_results = await asyncio.to_thread(
            pinecone_index.query,
            vector=question_embedding,
            top_k=top_k,
            include_metadata=True
        )

        logger.debug(f"   –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(search_results.matches)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")

        # --- 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
        contexts = []
        sources = []

        if search_results.matches:
            for match in search_results.matches:
                metadata = match.metadata or {}
                # –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –∫–ª—é—á–∏ –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–∞—à–∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Pinecone
                text = metadata.get('content') or metadata.get('title') or metadata.get('preview')  or f"–î–æ–∫—É–º–µ–Ω—Ç ID: {match.id}"
                contexts.append(text)

                source = metadata.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
                sources.append(source)
        else:
            logger.info("   –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.")
            contexts.append("–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.")
            sources.append("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")

        logger.debug(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(contexts)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        return contexts, sources

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Pinecone: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return ["–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"], ["Pinecone"]

async def generate_with_gemini(question: str, contexts: List[str]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini."""
    if not gemini_model:
        logger.warning("–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return "–ú–æ–¥–µ–ª—å Google Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    try:
        context_text = "\n\n".join(contexts)
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if len(context_text) > MAX_CONTEXT_LENGTH:
            context_text = context_text[:MAX_CONTEXT_LENGTH] + f"... (–∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
            logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤.")

        prompt = f"""
        –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å, –æ–ø–∏—Ä–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        –û—Ç–≤–µ—á–∞–π —è—Å–Ω–æ, —Ç–æ—á–Ω–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É.
        –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–∫–∞–∂–∏: "–Ø –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É."

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context_text}

        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç:
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Google Gemini...")
        response = gemini_model.generate_content(prompt)
        answer = response.text.strip()
        logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Google Gemini —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Google Gemini: {str(e)}"

async def generate_with_yandex(question: str, contexts: List[str]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT."""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        logger.warning("Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    try:
        context_text = "\n\n".join(contexts)
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if len(context_text) > MAX_CONTEXT_LENGTH:
            context_text = context_text[:MAX_CONTEXT_LENGTH] + f"... (–∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
            logger.info(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–µ—á–µ–Ω –¥–æ {MAX_CONTEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤.")

        prompt = f"""
        –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å, –æ–ø–∏—Ä–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        –û—Ç–≤–µ—á–∞–π —è—Å–Ω–æ, —Ç–æ—á–Ω–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É.
        –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–∫–∞–∂–∏: "–Ø –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É."

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context_text}

        –í–æ–ø—Ä–æ—Å: {question}
        –û—Ç–≤–µ—Ç:
        """.strip()

        logger.debug("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Yandex GPT...")
        async with httpx.AsyncClient() as client:
            yandex_response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.1,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            yandex_response.raise_for_status()
            yandex_data = yandex_response.json()
            answer = yandex_data['result']['alternatives'][0]['message']['text'].strip()
            logger.debug("‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Yandex GPT —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")
            return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Yandex GPT: {str(e)}"

async def generate_without_context(question: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è)"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è.
    –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ.
    –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —Å–∫–∞–∂–∏.
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_without_context_yandex(question: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Yandex GPT"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è.
    –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ.
    –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —Å–∫–∞–∂–∏.
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.7,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            response.raise_for_status()
            data = response.json()
            return data['result']['alternatives'][0]['message']['text'].strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ Yandex: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_with_context(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ Gemini"""
    if not gemini_model:
        return "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
    
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    {context}
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

async def generate_with_context_yandex(question: str, context: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —á–µ—Ä–µ–∑ Yandex GPT"""
    if not YANDEX_API_KEY or not YANDEX_FOLDER_ID:
        return "Yandex GPT –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    prompt = f"""
    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
    
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
    {context}
    
    –í–æ–ø—Ä–æ—Å: {question}
    –û—Ç–≤–µ—Ç:
    """

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                'https://llm.api.cloud.yandex.net/foundationModels/v1/completion',
                headers={
                    'Authorization': f'Api-Key {YANDEX_API_KEY}',
                    'x-folder-id': YANDEX_FOLDER_ID,
                    'Content-Type': 'application/json'
                },
                json={
                    'modelUri': YANDEX_GPT_MODEL_URI,
                    'completionOptions': {
                        'stream': False,
                        'temperature': 0.7,
                        'maxTokens': '2000'
                    },
                    'messages': [
                        {'role': 'system', 'text': '–¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.'},
                        {'role': 'user', 'text': prompt}
                    ]
                },
                timeout=60.0
            )
            response.raise_for_status()
            data = response.json()
            return data['result']['alternatives'][0]['message']['text'].strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º Yandex: {e}")
        return f"–û—à–∏–±–∫–∞: {str(e)}"

def search_open_sources(question: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"""
    sources = []

    # 1. PubMed Central API (—Ä–∞–±–æ—Ç–∞–µ—Ç)
    try:
        logger.debug("–ü–æ–∏—Å–∫ –≤ PubMed Central...")
        pmc_results = search_pubmed_central(question)
        if pmc_results:
            sources.extend(pmc_results)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ PubMed Central: {e}")

    # 2. MedlinePlus API (—Ä–∞–±–æ—Ç–∞–µ—Ç)
    try:
        logger.debug("–ü–æ–∏—Å–∫ –≤ MedlinePlus...")
        medline_results = search_medlineplus(question)
        if medline_results:
            sources.extend(medline_results)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ MedlinePlus: {e}")

    # 3. WHO GHO API (—Ä–∞–±–æ—Ç–∞–µ—Ç)
    try:
        logger.debug("–ü–æ–∏—Å–∫ –≤ WHO GHO...")
        who_results = search_who_gho(question)
        if who_results:
            sources.extend(who_results)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ WHO GHO: {e}")

    # 4. –í–µ–±-—Å–∞–π—Ç—ã (—á–µ—Ä–µ–∑ scraping - –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
    try:
        logger.debug("–ü–æ–∏—Å–∫ –≤ –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö...")
        web_results = search_web_sources(question)
        if web_results:
            sources.extend(web_results)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö: {e}")

    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    if not sources:
        sources.append({
            "name": "–û–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
            "url": "https://medlineplus.gov",
            "content": f"–î–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{question}' —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:\n" +
                       "- MedlinePlus (NIH)\n" +
                       "- –í—Å–µ–º–∏—Ä–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (WHO)\n" +
                       "- PubMed Central\n" +
                       "- –¶–µ–Ω—Ç—Ä—ã –ø–æ –∫–æ–Ω—Ç—Ä–æ–ª—é –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π (CDC)"
        })

    return sources[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

def search_pubmed_central(query: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –≤ PubMed Central"""
    try:
        url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
        params = {
            'db': 'pmc',
            'term': query,
            'retmax': 3,
            'format': 'json',
            'sort': 'relevance'
        }

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        results = []
        if 'idlist' in data['esearchresult']:
            pmc_ids = data['esearchresult']['idlist'][:2]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2

            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ —Å—Ç–∞—Ç–µ–π
            for pmc_id in pmc_ids:
                try:
                    summary_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
                    summary_params = {
                        'db': 'pmc',
                        'id': pmc_id,
                        'format': 'json'
                    }
                    summary_response = requests.get(summary_url, params=summary_params, timeout=5)
                    summary_response.raise_for_status()
                    summary_data = summary_response.json()

                    if str(pmc_id) in summary_data['result']:
                        article_info = summary_data['result'][str(pmc_id)]
                        title = article_info.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                        authors = article_info.get('authors', [])
                        author_names = [author.get('name', '') for author in authors[:3]]
                        authors_str = ', '.join(author_names) if author_names else '–ê–≤—Ç–æ—Ä—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã'

                        results.append({
                            "name": f"PubMed Central: {title[:100]}...",
                            "url": f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/",
                            "content": f"–ù–∞—É—á–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø–æ —Ç–µ–º–µ '{query}'. –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}. –ê–≤—Ç–æ—Ä—ã: {authors_str}"
                        })
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π —Å—Ç–∞—Ç—å–∏ PMC{pmc_id}: {e}")
                    continue

        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ PubMed Central: {e}")
        return []

def search_medlineplus(query: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ MedlinePlus"""
    try:
        url = "https://wsearch.nlm.nih.gov/ws/query"
        params = {
            'db': 'healthTopics',
            'term': query,
            'retmax': 2
        }

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        results = []
        if '<list>' in response.text:
            # –ü–∞—Ä—Å–∏–º XML –æ—Ç–≤–µ—Ç
            import xml.etree.ElementTree as ET
            try:
                root = ET.fromstring(response.text)
                items = root.findall('.//item')[:2]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2

                for item in items:
                    title_elem = item.find('title')
                    url_elem = item.find('url')
                    title = title_elem.text if title_elem is not None else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                    url = url_elem.text if url_elem is not None else 'https://medlineplus.gov'

                    results.append({
                        "name": f"MedlinePlus: {title[:100]}...",
                        "url": url,
                        "content": f"–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ '{query}' –æ—Ç –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤ –∑–¥–æ—Ä–æ–≤—å—è –°–®–ê. –¢–µ–º–∞: {title}"
                    })
            except Exception as xml_error:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML MedlinePlus: {xml_error}")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                results.append({
                    "name": "MedlinePlus",
                    "url": "https://medlineplus.gov",
                    "content": f"–û–±—â–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –¥–æ—Å—Ç—É–ø–Ω–∞ –Ω–∞ MedlinePlus - –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ NIH"
                })

        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ MedlinePlus: {e}")
        return []

def search_who_gho(query: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ WHO Global Health Observatory"""
    try:
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        indicators_url = "https://ghoapi.azureedge.net/api/Indicator"
        indicators_response = requests.get(indicators_url, timeout=10)
        indicators_response.raise_for_status()
        indicators_data = indicators_response.json()

        results = []
        found_indicators = []

        # –ò—â–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∑–∞–ø—Ä–æ—Å–æ–º
        if 'value' in indicators_data:
            for indicator in indicators_data['value'][:50]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 50
                indicator_title = indicator.get('IndicatorName', '').lower()
                if query.lower() in indicator_title or any(word in indicator_title for word in query.lower().split()):
                    found_indicators.append(indicator)
                    if len(found_indicators) >= 2:
                        break

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º
        for indicator in found_indicators[:2]:
            indicator_code = indicator.get('IndicatorCode', '')
            indicator_name = indicator.get('IndicatorName', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')

            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
            data_url = f"https://ghoapi.azureedge.net/api/{indicator_code}?$top=3"
            try:
                data_response = requests.get(data_url, timeout=10)
                data_response.raise_for_status()
                data = data_response.json()

                if 'value' in data and len(data['value']) > 0:
                    sample_data = data['value'][0]
                    country = sample_data.get('SpatialDim', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                    value = sample_data.get('NumericValue', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')
                    year = sample_data.get('TimeDim', '–ì–æ–¥ –Ω–µ —É–∫–∞–∑–∞–Ω')

                    results.append({
                        "name": f"WHO GHO: {indicator_name[:80]}...",
                        "url": "https://www.who.int/data/gho",
                        "content": f"–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ '{indicator_name}'. –ü—Ä–∏–º–µ—Ä: {country}, {year} - {value}"
                    })
            except Exception as data_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—É {indicator_code}: {data_error}")
                results.append({
                    "name": f"WHO GHO: {indicator_name[:80]}...",
                    "url": "https://www.who.int/data/gho",
                    "content": f"–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ '{indicator_name}' –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –í–û–ó"
                })

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if not results:
            results.append({
                "name": "WHO Global Health Observatory",
                "url": "https://www.who.int/data/gho",
                "content": f"–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ '{query}' –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –í—Å–µ–º–∏—Ä–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"
            })

        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ WHO GHO: {e}")
        return []

def search_web_sources(query: str) -> List[dict]:
    """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∞–π—Ç—ã (–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)"""
    results = []

    # WHO —Å–∞–π—Ç
    results.append({
        "name": "WHO - –í—Å–µ–º–∏—Ä–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
        "url": "https://www.who.int",
        "content": f"–ì–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ '{query}'. " +
                   "–í–û–ó –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è—Ö, –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏."
    })

    # CDC —Å–∞–π—Ç
    results.append({
        "name": "CDC - –¶–µ–Ω—Ç—Ä—ã –ø–æ –∫–æ–Ω—Ç—Ä–æ–ª—é –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –°–®–ê",
        "url": "https://www.cdc.gov",
        "content": f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∏ –ª–µ—á–µ–Ω–∏–∏ '{query}' –æ—Ç –¶–µ–Ω—Ç—Ä–æ–≤ –ø–æ –∫–æ–Ω—Ç—Ä–æ–ª—é –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –°–®–ê. " +
                   "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º."
    })

    # NIH —Å–∞–π—Ç
    results.append({
        "name": "NIH - –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç–∏—Ç—É—Ç—ã –∑–¥–æ—Ä–æ–≤—å—è –°–®–ê",
        "url": "https://www.nih.gov",
        "content": f"–ù–∞—É—á–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ '{query}' –æ—Ç –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤ –∑–¥–æ—Ä–æ–≤—å—è –°–®–ê. " +
                   "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–∞—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
    })

    return results[:2]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞–∫—Å–∏–º—É–º 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã API ---
@app.get("/")
async def home():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
    try:
        vector_count = 0
        dimension = 'N/A'
        if pinecone_index:
            try:
                stats = pinecone_index.describe_index_stats()
                vector_count = stats.get('total_vector_count', 0)
                dimension = stats.get('dimension', 'N/A')
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Pinecone –≤ /: {e}")
                vector_count = f"–û—à–∏–±–∫–∞: {e}"
        else:
            vector_count = "–ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"

        return {
            "status": "ok",
            "message": "Medical RAG API Server (Pinecone Llama Embeddings + Vertex AI)",
            "version": "3.4.0-Pinecone-Llama-Only",
            "pinecone_vectors": vector_count,
            "vector_dimension": dimension,
            "pinecone_embedding_model": "llama-text-embed-v2",
            "models_initialized": {
                "gemini_model": gemini_model is not None,
                "pinecone_index": pinecone_index is not None,
                "pinecone_client": pinecone_client is not None
            },
            "initialization_error": INITIALIZATION_ERROR
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Pinecone
        pinecone_status = "uninitialized"
        vector_count = 0
        dimension = 'N/A'
        if pinecone_index is not None:
            try:
                stats = pinecone_index.describe_index_stats()
                pinecone_status = "healthy"
                vector_count = stats.get('total_vector_count', 0)
                dimension = stats.get('dimension', 'N/A')
            except Exception as e:
                pinecone_status = "unhealthy"
                logger.error(f"Health check - Pinecone error: {e}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
        gemini_model_status = "healthy" if gemini_model is not None else "uninitialized"
        pinecone_client_status = "healthy" if pinecone_client is not None else "uninitialized"
        pinecone_index_status = "healthy" if pinecone_index is not None else "uninitialized"

        overall_status = "healthy"
        if not all([
            pinecone_status == "healthy",
            gemini_model_status == "healthy",
            pinecone_client_status == "healthy",
            pinecone_index_status == "healthy"
        ]):
            if INITIALIZATION_ERROR:
                overall_status = "unhealthy"
            else:
                overall_status = "degraded"

        return {
            "status": overall_status,
            "components": {
                "pinecone": {
                    "status": pinecone_status,
                    "vector_count": vector_count,
                    "dimension": dimension,
                    "embedding_model": "llama-text-embed-v2"
                },
                "gemini_model": {
                    "status": gemini_model_status
                },
                "pinecone_client": {
                    "status": pinecone_client_status
                },
                "pinecone_index": {
                    "status": pinecone_index_status
                }
            },
            "initialization_error": INITIALIZATION_ERROR,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ /health: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """
    –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG.
    –†–µ–∂–∏–º—ã:
    - knowledge_base: —Ç–æ–ª—å–∫–æ –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    - combined_ai: –ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ò–ò
    - unified_ai: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    - open_sources: –ø–æ–∏—Å–∫ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º + –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ò–ò
    """
    question = request.question.strip()
    mode = request.mode
    logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: {question} (—Ä–µ–∂–∏–º: {mode})")

    # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not question:
        logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å")
        raise HTTPException(status_code=400, detail="–í–æ–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    if len(question) > 1000:
        logger.warning(f"–ü–æ–ª—É—á–µ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å ({len(question)} —Å–∏–º–≤–æ–ª–æ–≤)")
        raise HTTPException(status_code=400, detail="–í–æ–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º 1000 —Å–∏–º–≤–æ–ª–æ–≤)")

    try:
        answer = ""
        sources = []

        if mode == "knowledge_base":
            # –¢–æ–ª—å–∫–æ –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            contexts, sources = await search_knowledge_base(question, top_k=3)
            answer = "–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n\n" + "\n\n---\n\n".join(contexts)

        elif mode == "combined_ai":
            # –ü–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ò–ò + –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            contexts, sources = await search_knowledge_base(question, top_k=3)
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(contexts)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            if not contexts or contexts == ["–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"]:
                answer = "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
                sources = ["–°–∏—Å—Ç–µ–º–∞"]
            else:
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                tasks = []
                models_used = []

                if gemini_model:
                    tasks.append(generate_with_gemini(question, contexts))
                    models_used.append("Google Gemini")
                if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                    tasks.append(generate_with_yandex(question, contexts))
                    models_used.append("Yandex GPT")

                if tasks:
                    answers = await asyncio.gather(*tasks, return_exceptions=True)

                    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                    model_answers = []
                    for model_name, ans in zip(models_used, answers):
                        if isinstance(ans, Exception):
                            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                            model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                        else:
                            model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    unified_prompt = f"""
                    –í–æ–ø—Ä–æ—Å: {question}
                    
                    –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                    {'\n\n'.join(model_answers)}
                    
                    –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                    –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                    """

                    unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                    if gemini_model:
                        try:
                            unified_answer = await generate_with_gemini(unified_prompt, [])
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                    answer_parts = model_answers.copy()
                    answer_parts.append(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}")
                    answer = "\n\n---\n\n".join(answer_parts)
                else:
                    answer = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
                    sources = ["–°–∏—Å—Ç–µ–º–∞"]

        elif mode == "unified_ai":
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –ò–ò –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            answer = "üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...\n\n"

            tasks = []
            models_used = []

            if gemini_model:
                tasks.append(generate_without_context(question))
                models_used.append("Google Gemini")
            if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                tasks.append(generate_without_context_yandex(question))
                models_used.append("Yandex GPT")

            if tasks:
                answers = await asyncio.gather(*tasks, return_exceptions=True)

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                model_answers = []
                for model_name, ans in zip(models_used, answers):
                    if isinstance(ans, Exception):
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                        model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                    else:
                        model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                unified_prompt = f"""
                –í–æ–ø—Ä–æ—Å: {question}
                
                –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                {'\n\n'.join(model_answers)}
                
                –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                """

                unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                if gemini_model:
                    try:
                        unified_response = gemini_model.generate_content(unified_prompt)
                        unified_answer = unified_response.text.strip()
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                answer_parts = model_answers.copy()
                answer_parts.append(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}")
                answer += "\n\n---\n\n".join(answer_parts)
                sources = ["Google Gemini", "Yandex GPT", "–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
            else:
                answer = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞"
                sources = ["–°–∏—Å—Ç–µ–º–∞"]

        elif mode == "open_sources":
            # –ü–æ–∏—Å–∫ –ø–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º + –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ò–ò
            open_sources_info = search_open_sources(question)
            sources = [src["name"] for src in open_sources_info]

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            open_contexts = []
            for src in open_sources_info:
                open_contexts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {src['name']}\n{src['content']}")

            context_text = "\n\n".join(open_contexts) if open_contexts else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ò–ò –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            tasks = []
            models_used = []

            if gemini_model:
                tasks.append(generate_with_context(question, context_text))
                models_used.append("Google Gemini")
            if YANDEX_API_KEY and YANDEX_FOLDER_ID:
                tasks.append(generate_with_context_yandex(question, context_text))
                models_used.append("Yandex GPT")

            if tasks:
                answers = await asyncio.gather(*tasks, return_exceptions=True)

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                model_answers = []
                for model_name, ans in zip(models_used, answers):
                    if isinstance(ans, Exception):
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {model_name}: {ans}")
                        model_answers.append(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç {model_name}")
                    else:
                        model_answers.append(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n{ans}")

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                unified_prompt = f"""
                –í–æ–ø—Ä–æ—Å: {question}
                
                –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
                {context_text}
                
                –û—Ç–≤–µ—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
                {'\n\n'.join(model_answers)}
                
                –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
                –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                """

                unified_answer = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç"
                if gemini_model:
                    try:
                        unified_response = gemini_model.generate_content(unified_prompt)
                        unified_answer = unified_response.text.strip()
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                answer_parts = [
                    f"üìö –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n{context_text}",
                    *model_answers,
                    f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n{unified_answer}"
                ]
                answer = "\n\n---\n\n".join(answer_parts)
            else:
                answer = f"üìö –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n{context_text}\n\n–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ò–ò –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        else:
            raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ä–µ–∂–∏–º")

        logger.info("‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
        return AnswerResponse(
            question=question,
            answer=answer,
            sources=sources,
            mode=mode
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ /ask: {e}")
        logger.error(f"   Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

# --- –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ ---
if __name__ == "__main__":
    import uvicorn
    from datetime import datetime
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π Cloud Run/Render
    port = int(os.environ.get("PORT", 8080))
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ Uvicorn –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    # –í–ê–ñ–ù–û: host –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "0.0.0.0" –¥–ª—è Cloud Run/Render
    uvicorn.run(app, host="0.0.0.0", port=port)
